{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2380,"sourceType":"datasetVersion","datasetId":1320}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-05T16:15:29.661685Z","iopub.execute_input":"2024-12-05T16:15:29.662528Z","iopub.status.idle":"2024-12-05T16:15:29.666596Z","shell.execute_reply.started":"2024-12-05T16:15:29.662492Z","shell.execute_reply":"2024-12-05T16:15:29.665684Z"}},"outputs":[],"execution_count":106},{"cell_type":"code","source":"data=pd.read_csv('/kaggle/input/mines-vs-rocks/sonar.all-data.csv',header=None)\ndata.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T16:15:29.671170Z","iopub.execute_input":"2024-12-05T16:15:29.671529Z","iopub.status.idle":"2024-12-05T16:15:29.705250Z","shell.execute_reply.started":"2024-12-05T16:15:29.671482Z","shell.execute_reply":"2024-12-05T16:15:29.704371Z"}},"outputs":[{"execution_count":107,"output_type":"execute_result","data":{"text/plain":"       0       1       2       3       4       5       6       7       8   \\\n0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n5  0.0286  0.0453  0.0277  0.0174  0.0384  0.0990  0.1201  0.1833  0.2105   \n6  0.0317  0.0956  0.1321  0.1408  0.1674  0.1710  0.0731  0.1401  0.2083   \n7  0.0519  0.0548  0.0842  0.0319  0.1158  0.0922  0.1027  0.0613  0.1465   \n8  0.0223  0.0375  0.0484  0.0475  0.0647  0.0591  0.0753  0.0098  0.0684   \n9  0.0164  0.0173  0.0347  0.0070  0.0187  0.0671  0.1056  0.0697  0.0962   \n\n       9   ...      51      52      53      54      55      56      57  \\\n0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n5  0.3039  ...  0.0045  0.0014  0.0038  0.0013  0.0089  0.0057  0.0027   \n6  0.3513  ...  0.0201  0.0248  0.0131  0.0070  0.0138  0.0092  0.0143   \n7  0.2838  ...  0.0081  0.0120  0.0045  0.0121  0.0097  0.0085  0.0047   \n8  0.1487  ...  0.0145  0.0128  0.0145  0.0058  0.0049  0.0065  0.0093   \n9  0.0251  ...  0.0090  0.0223  0.0179  0.0084  0.0068  0.0032  0.0035   \n\n       58      59  60  \n0  0.0090  0.0032   R  \n1  0.0052  0.0044   R  \n2  0.0095  0.0078   R  \n3  0.0040  0.0117   R  \n4  0.0107  0.0094   R  \n5  0.0051  0.0062   R  \n6  0.0036  0.0103   R  \n7  0.0048  0.0053   R  \n8  0.0059  0.0022   R  \n9  0.0056  0.0040   R  \n\n[10 rows x 61 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>51</th>\n      <th>52</th>\n      <th>53</th>\n      <th>54</th>\n      <th>55</th>\n      <th>56</th>\n      <th>57</th>\n      <th>58</th>\n      <th>59</th>\n      <th>60</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0200</td>\n      <td>0.0371</td>\n      <td>0.0428</td>\n      <td>0.0207</td>\n      <td>0.0954</td>\n      <td>0.0986</td>\n      <td>0.1539</td>\n      <td>0.1601</td>\n      <td>0.3109</td>\n      <td>0.2111</td>\n      <td>...</td>\n      <td>0.0027</td>\n      <td>0.0065</td>\n      <td>0.0159</td>\n      <td>0.0072</td>\n      <td>0.0167</td>\n      <td>0.0180</td>\n      <td>0.0084</td>\n      <td>0.0090</td>\n      <td>0.0032</td>\n      <td>R</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0453</td>\n      <td>0.0523</td>\n      <td>0.0843</td>\n      <td>0.0689</td>\n      <td>0.1183</td>\n      <td>0.2583</td>\n      <td>0.2156</td>\n      <td>0.3481</td>\n      <td>0.3337</td>\n      <td>0.2872</td>\n      <td>...</td>\n      <td>0.0084</td>\n      <td>0.0089</td>\n      <td>0.0048</td>\n      <td>0.0094</td>\n      <td>0.0191</td>\n      <td>0.0140</td>\n      <td>0.0049</td>\n      <td>0.0052</td>\n      <td>0.0044</td>\n      <td>R</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0262</td>\n      <td>0.0582</td>\n      <td>0.1099</td>\n      <td>0.1083</td>\n      <td>0.0974</td>\n      <td>0.2280</td>\n      <td>0.2431</td>\n      <td>0.3771</td>\n      <td>0.5598</td>\n      <td>0.6194</td>\n      <td>...</td>\n      <td>0.0232</td>\n      <td>0.0166</td>\n      <td>0.0095</td>\n      <td>0.0180</td>\n      <td>0.0244</td>\n      <td>0.0316</td>\n      <td>0.0164</td>\n      <td>0.0095</td>\n      <td>0.0078</td>\n      <td>R</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0100</td>\n      <td>0.0171</td>\n      <td>0.0623</td>\n      <td>0.0205</td>\n      <td>0.0205</td>\n      <td>0.0368</td>\n      <td>0.1098</td>\n      <td>0.1276</td>\n      <td>0.0598</td>\n      <td>0.1264</td>\n      <td>...</td>\n      <td>0.0121</td>\n      <td>0.0036</td>\n      <td>0.0150</td>\n      <td>0.0085</td>\n      <td>0.0073</td>\n      <td>0.0050</td>\n      <td>0.0044</td>\n      <td>0.0040</td>\n      <td>0.0117</td>\n      <td>R</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0762</td>\n      <td>0.0666</td>\n      <td>0.0481</td>\n      <td>0.0394</td>\n      <td>0.0590</td>\n      <td>0.0649</td>\n      <td>0.1209</td>\n      <td>0.2467</td>\n      <td>0.3564</td>\n      <td>0.4459</td>\n      <td>...</td>\n      <td>0.0031</td>\n      <td>0.0054</td>\n      <td>0.0105</td>\n      <td>0.0110</td>\n      <td>0.0015</td>\n      <td>0.0072</td>\n      <td>0.0048</td>\n      <td>0.0107</td>\n      <td>0.0094</td>\n      <td>R</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.0286</td>\n      <td>0.0453</td>\n      <td>0.0277</td>\n      <td>0.0174</td>\n      <td>0.0384</td>\n      <td>0.0990</td>\n      <td>0.1201</td>\n      <td>0.1833</td>\n      <td>0.2105</td>\n      <td>0.3039</td>\n      <td>...</td>\n      <td>0.0045</td>\n      <td>0.0014</td>\n      <td>0.0038</td>\n      <td>0.0013</td>\n      <td>0.0089</td>\n      <td>0.0057</td>\n      <td>0.0027</td>\n      <td>0.0051</td>\n      <td>0.0062</td>\n      <td>R</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.0317</td>\n      <td>0.0956</td>\n      <td>0.1321</td>\n      <td>0.1408</td>\n      <td>0.1674</td>\n      <td>0.1710</td>\n      <td>0.0731</td>\n      <td>0.1401</td>\n      <td>0.2083</td>\n      <td>0.3513</td>\n      <td>...</td>\n      <td>0.0201</td>\n      <td>0.0248</td>\n      <td>0.0131</td>\n      <td>0.0070</td>\n      <td>0.0138</td>\n      <td>0.0092</td>\n      <td>0.0143</td>\n      <td>0.0036</td>\n      <td>0.0103</td>\n      <td>R</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.0519</td>\n      <td>0.0548</td>\n      <td>0.0842</td>\n      <td>0.0319</td>\n      <td>0.1158</td>\n      <td>0.0922</td>\n      <td>0.1027</td>\n      <td>0.0613</td>\n      <td>0.1465</td>\n      <td>0.2838</td>\n      <td>...</td>\n      <td>0.0081</td>\n      <td>0.0120</td>\n      <td>0.0045</td>\n      <td>0.0121</td>\n      <td>0.0097</td>\n      <td>0.0085</td>\n      <td>0.0047</td>\n      <td>0.0048</td>\n      <td>0.0053</td>\n      <td>R</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.0223</td>\n      <td>0.0375</td>\n      <td>0.0484</td>\n      <td>0.0475</td>\n      <td>0.0647</td>\n      <td>0.0591</td>\n      <td>0.0753</td>\n      <td>0.0098</td>\n      <td>0.0684</td>\n      <td>0.1487</td>\n      <td>...</td>\n      <td>0.0145</td>\n      <td>0.0128</td>\n      <td>0.0145</td>\n      <td>0.0058</td>\n      <td>0.0049</td>\n      <td>0.0065</td>\n      <td>0.0093</td>\n      <td>0.0059</td>\n      <td>0.0022</td>\n      <td>R</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.0164</td>\n      <td>0.0173</td>\n      <td>0.0347</td>\n      <td>0.0070</td>\n      <td>0.0187</td>\n      <td>0.0671</td>\n      <td>0.1056</td>\n      <td>0.0697</td>\n      <td>0.0962</td>\n      <td>0.0251</td>\n      <td>...</td>\n      <td>0.0090</td>\n      <td>0.0223</td>\n      <td>0.0179</td>\n      <td>0.0084</td>\n      <td>0.0068</td>\n      <td>0.0032</td>\n      <td>0.0035</td>\n      <td>0.0056</td>\n      <td>0.0040</td>\n      <td>R</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows Ã— 61 columns</p>\n</div>"},"metadata":{}}],"execution_count":107},{"cell_type":"code","source":"data.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T16:15:29.706707Z","iopub.execute_input":"2024-12-05T16:15:29.707003Z","iopub.status.idle":"2024-12-05T16:15:29.712149Z","shell.execute_reply.started":"2024-12-05T16:15:29.706966Z","shell.execute_reply":"2024-12-05T16:15:29.711313Z"}},"outputs":[{"execution_count":108,"output_type":"execute_result","data":{"text/plain":"(208, 61)"},"metadata":{}}],"execution_count":108},{"cell_type":"code","source":"data.describe() #statistical measures of the data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T16:15:29.713268Z","iopub.execute_input":"2024-12-05T16:15:29.713503Z","iopub.status.idle":"2024-12-05T16:15:29.812095Z","shell.execute_reply.started":"2024-12-05T16:15:29.713479Z","shell.execute_reply":"2024-12-05T16:15:29.811363Z"}},"outputs":[{"execution_count":109,"output_type":"execute_result","data":{"text/plain":"               0           1           2           3           4           5   \\\ncount  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \nmean     0.029164    0.038437    0.043832    0.053892    0.075202    0.104570   \nstd      0.022991    0.032960    0.038428    0.046528    0.055552    0.059105   \nmin      0.001500    0.000600    0.001500    0.005800    0.006700    0.010200   \n25%      0.013350    0.016450    0.018950    0.024375    0.038050    0.067025   \n50%      0.022800    0.030800    0.034300    0.044050    0.062500    0.092150   \n75%      0.035550    0.047950    0.057950    0.064500    0.100275    0.134125   \nmax      0.137100    0.233900    0.305900    0.426400    0.401000    0.382300   \n\n               6           7           8           9   ...          50  \\\ncount  208.000000  208.000000  208.000000  208.000000  ...  208.000000   \nmean     0.121747    0.134799    0.178003    0.208259  ...    0.016069   \nstd      0.061788    0.085152    0.118387    0.134416  ...    0.012008   \nmin      0.003300    0.005500    0.007500    0.011300  ...    0.000000   \n25%      0.080900    0.080425    0.097025    0.111275  ...    0.008425   \n50%      0.106950    0.112100    0.152250    0.182400  ...    0.013900   \n75%      0.154000    0.169600    0.233425    0.268700  ...    0.020825   \nmax      0.372900    0.459000    0.682800    0.710600  ...    0.100400   \n\n               51          52          53          54          55          56  \\\ncount  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \nmean     0.013420    0.010709    0.010941    0.009290    0.008222    0.007820   \nstd      0.009634    0.007060    0.007301    0.007088    0.005736    0.005785   \nmin      0.000800    0.000500    0.001000    0.000600    0.000400    0.000300   \n25%      0.007275    0.005075    0.005375    0.004150    0.004400    0.003700   \n50%      0.011400    0.009550    0.009300    0.007500    0.006850    0.005950   \n75%      0.016725    0.014900    0.014500    0.012100    0.010575    0.010425   \nmax      0.070900    0.039000    0.035200    0.044700    0.039400    0.035500   \n\n               57          58          59  \ncount  208.000000  208.000000  208.000000  \nmean     0.007949    0.007941    0.006507  \nstd      0.006470    0.006181    0.005031  \nmin      0.000300    0.000100    0.000600  \n25%      0.003600    0.003675    0.003100  \n50%      0.005800    0.006400    0.005300  \n75%      0.010350    0.010325    0.008525  \nmax      0.044000    0.036400    0.043900  \n\n[8 rows x 60 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>50</th>\n      <th>51</th>\n      <th>52</th>\n      <th>53</th>\n      <th>54</th>\n      <th>55</th>\n      <th>56</th>\n      <th>57</th>\n      <th>58</th>\n      <th>59</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>208.000000</td>\n      <td>208.000000</td>\n      <td>208.000000</td>\n      <td>208.000000</td>\n      <td>208.000000</td>\n      <td>208.000000</td>\n      <td>208.000000</td>\n      <td>208.000000</td>\n      <td>208.000000</td>\n      <td>208.000000</td>\n      <td>...</td>\n      <td>208.000000</td>\n      <td>208.000000</td>\n      <td>208.000000</td>\n      <td>208.000000</td>\n      <td>208.000000</td>\n      <td>208.000000</td>\n      <td>208.000000</td>\n      <td>208.000000</td>\n      <td>208.000000</td>\n      <td>208.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.029164</td>\n      <td>0.038437</td>\n      <td>0.043832</td>\n      <td>0.053892</td>\n      <td>0.075202</td>\n      <td>0.104570</td>\n      <td>0.121747</td>\n      <td>0.134799</td>\n      <td>0.178003</td>\n      <td>0.208259</td>\n      <td>...</td>\n      <td>0.016069</td>\n      <td>0.013420</td>\n      <td>0.010709</td>\n      <td>0.010941</td>\n      <td>0.009290</td>\n      <td>0.008222</td>\n      <td>0.007820</td>\n      <td>0.007949</td>\n      <td>0.007941</td>\n      <td>0.006507</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.022991</td>\n      <td>0.032960</td>\n      <td>0.038428</td>\n      <td>0.046528</td>\n      <td>0.055552</td>\n      <td>0.059105</td>\n      <td>0.061788</td>\n      <td>0.085152</td>\n      <td>0.118387</td>\n      <td>0.134416</td>\n      <td>...</td>\n      <td>0.012008</td>\n      <td>0.009634</td>\n      <td>0.007060</td>\n      <td>0.007301</td>\n      <td>0.007088</td>\n      <td>0.005736</td>\n      <td>0.005785</td>\n      <td>0.006470</td>\n      <td>0.006181</td>\n      <td>0.005031</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.001500</td>\n      <td>0.000600</td>\n      <td>0.001500</td>\n      <td>0.005800</td>\n      <td>0.006700</td>\n      <td>0.010200</td>\n      <td>0.003300</td>\n      <td>0.005500</td>\n      <td>0.007500</td>\n      <td>0.011300</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000800</td>\n      <td>0.000500</td>\n      <td>0.001000</td>\n      <td>0.000600</td>\n      <td>0.000400</td>\n      <td>0.000300</td>\n      <td>0.000300</td>\n      <td>0.000100</td>\n      <td>0.000600</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.013350</td>\n      <td>0.016450</td>\n      <td>0.018950</td>\n      <td>0.024375</td>\n      <td>0.038050</td>\n      <td>0.067025</td>\n      <td>0.080900</td>\n      <td>0.080425</td>\n      <td>0.097025</td>\n      <td>0.111275</td>\n      <td>...</td>\n      <td>0.008425</td>\n      <td>0.007275</td>\n      <td>0.005075</td>\n      <td>0.005375</td>\n      <td>0.004150</td>\n      <td>0.004400</td>\n      <td>0.003700</td>\n      <td>0.003600</td>\n      <td>0.003675</td>\n      <td>0.003100</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.022800</td>\n      <td>0.030800</td>\n      <td>0.034300</td>\n      <td>0.044050</td>\n      <td>0.062500</td>\n      <td>0.092150</td>\n      <td>0.106950</td>\n      <td>0.112100</td>\n      <td>0.152250</td>\n      <td>0.182400</td>\n      <td>...</td>\n      <td>0.013900</td>\n      <td>0.011400</td>\n      <td>0.009550</td>\n      <td>0.009300</td>\n      <td>0.007500</td>\n      <td>0.006850</td>\n      <td>0.005950</td>\n      <td>0.005800</td>\n      <td>0.006400</td>\n      <td>0.005300</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.035550</td>\n      <td>0.047950</td>\n      <td>0.057950</td>\n      <td>0.064500</td>\n      <td>0.100275</td>\n      <td>0.134125</td>\n      <td>0.154000</td>\n      <td>0.169600</td>\n      <td>0.233425</td>\n      <td>0.268700</td>\n      <td>...</td>\n      <td>0.020825</td>\n      <td>0.016725</td>\n      <td>0.014900</td>\n      <td>0.014500</td>\n      <td>0.012100</td>\n      <td>0.010575</td>\n      <td>0.010425</td>\n      <td>0.010350</td>\n      <td>0.010325</td>\n      <td>0.008525</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.137100</td>\n      <td>0.233900</td>\n      <td>0.305900</td>\n      <td>0.426400</td>\n      <td>0.401000</td>\n      <td>0.382300</td>\n      <td>0.372900</td>\n      <td>0.459000</td>\n      <td>0.682800</td>\n      <td>0.710600</td>\n      <td>...</td>\n      <td>0.100400</td>\n      <td>0.070900</td>\n      <td>0.039000</td>\n      <td>0.035200</td>\n      <td>0.044700</td>\n      <td>0.039400</td>\n      <td>0.035500</td>\n      <td>0.044000</td>\n      <td>0.036400</td>\n      <td>0.043900</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows Ã— 60 columns</p>\n</div>"},"metadata":{}}],"execution_count":109},{"cell_type":"code","source":"data[60].value_counts() ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T16:15:29.813828Z","iopub.execute_input":"2024-12-05T16:15:29.814113Z","iopub.status.idle":"2024-12-05T16:15:29.820472Z","shell.execute_reply.started":"2024-12-05T16:15:29.814086Z","shell.execute_reply":"2024-12-05T16:15:29.819607Z"}},"outputs":[{"execution_count":110,"output_type":"execute_result","data":{"text/plain":"60\nM    111\nR     97\nName: count, dtype: int64"},"metadata":{}}],"execution_count":110},{"cell_type":"code","source":"data.groupby(60).mean()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T16:15:29.821347Z","iopub.execute_input":"2024-12-05T16:15:29.821613Z","iopub.status.idle":"2024-12-05T16:15:29.844812Z","shell.execute_reply.started":"2024-12-05T16:15:29.821567Z","shell.execute_reply":"2024-12-05T16:15:29.844048Z"}},"outputs":[{"execution_count":111,"output_type":"execute_result","data":{"text/plain":"          0         1         2         3         4         5         6   \\\n60                                                                         \nM   0.034989  0.045544  0.050720  0.064768  0.086715  0.111864  0.128359   \nR   0.022498  0.030303  0.035951  0.041447  0.062028  0.096224  0.114180   \n\n          7         8         9   ...        50        51        52        53  \\\n60                                ...                                           \nM   0.149832  0.213492  0.251022  ...  0.019352  0.016014  0.011643  0.012185   \nR   0.117596  0.137392  0.159325  ...  0.012311  0.010453  0.009640  0.009518   \n\n          54        55        56        57        58        59  \n60                                                              \nM   0.009923  0.008914  0.007825  0.009060  0.008695  0.006930  \nR   0.008567  0.007430  0.007814  0.006677  0.007078  0.006024  \n\n[2 rows x 60 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>50</th>\n      <th>51</th>\n      <th>52</th>\n      <th>53</th>\n      <th>54</th>\n      <th>55</th>\n      <th>56</th>\n      <th>57</th>\n      <th>58</th>\n      <th>59</th>\n    </tr>\n    <tr>\n      <th>60</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>M</th>\n      <td>0.034989</td>\n      <td>0.045544</td>\n      <td>0.050720</td>\n      <td>0.064768</td>\n      <td>0.086715</td>\n      <td>0.111864</td>\n      <td>0.128359</td>\n      <td>0.149832</td>\n      <td>0.213492</td>\n      <td>0.251022</td>\n      <td>...</td>\n      <td>0.019352</td>\n      <td>0.016014</td>\n      <td>0.011643</td>\n      <td>0.012185</td>\n      <td>0.009923</td>\n      <td>0.008914</td>\n      <td>0.007825</td>\n      <td>0.009060</td>\n      <td>0.008695</td>\n      <td>0.006930</td>\n    </tr>\n    <tr>\n      <th>R</th>\n      <td>0.022498</td>\n      <td>0.030303</td>\n      <td>0.035951</td>\n      <td>0.041447</td>\n      <td>0.062028</td>\n      <td>0.096224</td>\n      <td>0.114180</td>\n      <td>0.117596</td>\n      <td>0.137392</td>\n      <td>0.159325</td>\n      <td>...</td>\n      <td>0.012311</td>\n      <td>0.010453</td>\n      <td>0.009640</td>\n      <td>0.009518</td>\n      <td>0.008567</td>\n      <td>0.007430</td>\n      <td>0.007814</td>\n      <td>0.006677</td>\n      <td>0.007078</td>\n      <td>0.006024</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows Ã— 60 columns</p>\n</div>"},"metadata":{}}],"execution_count":111},{"cell_type":"code","source":"X=data.drop(columns=60,axis=1)\nY=data[60]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T16:15:29.845709Z","iopub.execute_input":"2024-12-05T16:15:29.846015Z","iopub.status.idle":"2024-12-05T16:15:29.850500Z","shell.execute_reply.started":"2024-12-05T16:15:29.845982Z","shell.execute_reply":"2024-12-05T16:15:29.849637Z"}},"outputs":[],"execution_count":112},{"cell_type":"code","source":"print(X)\nprint(Y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T16:15:29.851506Z","iopub.execute_input":"2024-12-05T16:15:29.851752Z","iopub.status.idle":"2024-12-05T16:15:29.872839Z","shell.execute_reply.started":"2024-12-05T16:15:29.851727Z","shell.execute_reply":"2024-12-05T16:15:29.872132Z"}},"outputs":[{"name":"stdout","text":"         0       1       2       3       4       5       6       7       8   \\\n0    0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n1    0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n2    0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n3    0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n4    0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n203  0.0187  0.0346  0.0168  0.0177  0.0393  0.1630  0.2028  0.1694  0.2328   \n204  0.0323  0.0101  0.0298  0.0564  0.0760  0.0958  0.0990  0.1018  0.1030   \n205  0.0522  0.0437  0.0180  0.0292  0.0351  0.1171  0.1257  0.1178  0.1258   \n206  0.0303  0.0353  0.0490  0.0608  0.0167  0.1354  0.1465  0.1123  0.1945   \n207  0.0260  0.0363  0.0136  0.0272  0.0214  0.0338  0.0655  0.1400  0.1843   \n\n         9   ...      50      51      52      53      54      55      56  \\\n0    0.2111  ...  0.0232  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180   \n1    0.2872  ...  0.0125  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140   \n2    0.6194  ...  0.0033  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316   \n3    0.1264  ...  0.0241  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050   \n4    0.4459  ...  0.0156  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072   \n..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n203  0.2684  ...  0.0203  0.0116  0.0098  0.0199  0.0033  0.0101  0.0065   \n204  0.2154  ...  0.0051  0.0061  0.0093  0.0135  0.0063  0.0063  0.0034   \n205  0.2529  ...  0.0155  0.0160  0.0029  0.0051  0.0062  0.0089  0.0140   \n206  0.2354  ...  0.0042  0.0086  0.0046  0.0126  0.0036  0.0035  0.0034   \n207  0.2354  ...  0.0181  0.0146  0.0129  0.0047  0.0039  0.0061  0.0040   \n\n         57      58      59  \n0    0.0084  0.0090  0.0032  \n1    0.0049  0.0052  0.0044  \n2    0.0164  0.0095  0.0078  \n3    0.0044  0.0040  0.0117  \n4    0.0048  0.0107  0.0094  \n..      ...     ...     ...  \n203  0.0115  0.0193  0.0157  \n204  0.0032  0.0062  0.0067  \n205  0.0138  0.0077  0.0031  \n206  0.0079  0.0036  0.0048  \n207  0.0036  0.0061  0.0115  \n\n[208 rows x 60 columns]\n0      R\n1      R\n2      R\n3      R\n4      R\n      ..\n203    M\n204    M\n205    M\n206    M\n207    M\nName: 60, Length: 208, dtype: object\n","output_type":"stream"}],"execution_count":113},{"cell_type":"code","source":"#spliting\nfrom sklearn.model_selection import train_test_split\n\nx_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.1,stratify=Y,random_state=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T16:15:29.873889Z","iopub.execute_input":"2024-12-05T16:15:29.874220Z","iopub.status.idle":"2024-12-05T16:15:29.885444Z","shell.execute_reply.started":"2024-12-05T16:15:29.874186Z","shell.execute_reply":"2024-12-05T16:15:29.884828Z"}},"outputs":[],"execution_count":114},{"cell_type":"code","source":"print(X.shape,x_train.shape,x_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T16:15:29.886427Z","iopub.execute_input":"2024-12-05T16:15:29.886675Z","iopub.status.idle":"2024-12-05T16:15:29.896712Z","shell.execute_reply.started":"2024-12-05T16:15:29.886649Z","shell.execute_reply":"2024-12-05T16:15:29.895961Z"}},"outputs":[{"name":"stdout","text":"(208, 60) (187, 60) (21, 60)\n","output_type":"stream"}],"execution_count":115},{"cell_type":"code","source":"model = LogisticRegression()\n\n# Train the model\nmodel.fit(x_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T16:15:29.898669Z","iopub.execute_input":"2024-12-05T16:15:29.898906Z","iopub.status.idle":"2024-12-05T16:15:29.923588Z","shell.execute_reply.started":"2024-12-05T16:15:29.898883Z","shell.execute_reply":"2024-12-05T16:15:29.922651Z"}},"outputs":[{"execution_count":116,"output_type":"execute_result","data":{"text/plain":"LogisticRegression()","text/html":"<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":116},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n# Make predictions\ny_pred = model.predict(x_test)\n\n# Evaluate accuracy\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\n\n# Classification report (precision, recall, f1-score)\nprint(\"Classification Report:\")\nprint(classification_report(y_test, y_pred))\n\n# Confusion matrix\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T16:15:29.924754Z","iopub.execute_input":"2024-12-05T16:15:29.930247Z","iopub.status.idle":"2024-12-05T16:15:29.961418Z","shell.execute_reply.started":"2024-12-05T16:15:29.930181Z","shell.execute_reply":"2024-12-05T16:15:29.960381Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.7619047619047619\nClassification Report:\n              precision    recall  f1-score   support\n\n           M       0.75      0.82      0.78        11\n           R       0.78      0.70      0.74        10\n\n    accuracy                           0.76        21\n   macro avg       0.76      0.76      0.76        21\nweighted avg       0.76      0.76      0.76        21\n\nConfusion Matrix:\n[[9 2]\n [3 7]]\n","output_type":"stream"}],"execution_count":117},{"cell_type":"code","source":"#accuracy\nx_train_pred=model.predict(x_train)\ntraining_data_accu=accuracy_score(x_train_pred,y_train)\nprint(\"ACCURACY ON TRANIG DATA:-\",training_data_accu)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T16:15:29.962598Z","iopub.execute_input":"2024-12-05T16:15:29.965104Z","iopub.status.idle":"2024-12-05T16:15:29.986603Z","shell.execute_reply.started":"2024-12-05T16:15:29.965049Z","shell.execute_reply":"2024-12-05T16:15:29.985376Z"}},"outputs":[{"name":"stdout","text":"ACCURACY ON TRANIG DATA:- 0.8342245989304813\n","output_type":"stream"}],"execution_count":118},{"cell_type":"code","source":"#accuracy\nx_test_pred=model.predict(x_test)\ntest_data_accu=accuracy_score(x_test_pred,y_test)\nprint(\"ACCURACY ON TEST DATA:-\",test_data_accu)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T16:15:29.990151Z","iopub.execute_input":"2024-12-05T16:15:29.990585Z","iopub.status.idle":"2024-12-05T16:15:30.011651Z","shell.execute_reply.started":"2024-12-05T16:15:29.990536Z","shell.execute_reply":"2024-12-05T16:15:30.010342Z"}},"outputs":[{"name":"stdout","text":"ACCURACY ON TEST DATA:- 0.7619047619047619\n","output_type":"stream"}],"execution_count":119},{"cell_type":"code","source":"#predictions\ninput=(0.0099,0.0484,0.0299,0.0297,0.0652,0.1077,0.2363,0.2385,0.0075,0.1882,0.1456,0.1892,0.3176,0.1340,0.2169,0.2458,0.2589,0.2786,0.2298,0.0656,0.1441,0.1179,0.1668,0.1783,0.2476,0.2570,0.1036,0.5356,0.7124,0.6291,0.4756,0.6015,0.7208,0.6234,0.5725,0.7523,0.8712,0.9252,0.9709,0.9297,0.8995,0.7911,0.5600,0.2838,0.4407,0.5507,0.4331,0.2905,0.1981,0.0779,0.0396,0.0173,0.0149,0.0115,0.0202,0.0139,0.0029,0.0160,0.0106,0.0134\n      )\n#changeing input data to numpy array\nnp_arr=np.asarray(input)\n\n#reshpe the numpy array\nres_input=np_arr.reshape(1,-1)\n\npred=model.predict(res_input)\n\nif(pred[0]==\"R\"):\n    print(\"ROCK\")\nelse:\n    print(\"MINE\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T16:15:30.016048Z","iopub.execute_input":"2024-12-05T16:15:30.016510Z","iopub.status.idle":"2024-12-05T16:15:30.037099Z","shell.execute_reply.started":"2024-12-05T16:15:30.016461Z","shell.execute_reply":"2024-12-05T16:15:30.034575Z"}},"outputs":[{"name":"stdout","text":"ROCK\n","output_type":"stream"}],"execution_count":120}]}